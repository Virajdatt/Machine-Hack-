{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Before we move on to complex Deep Learning methods for building our classifier, here I am going to start with simple Machine Learning Classifiers like Decision-Tree, Random-Forest, Logistic Regression which are built from bag of words model. \n",
    "\n",
    "## The idea here is to establish a baseline model from where we can build on complex time taking deep learning models (lstm, transformers like BERT)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import sys; sys.path.insert(0, '..') # helps importing our modules\n",
    "from src import text_ops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "from textblob import TextBlob\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "raw_data = pd.read_csv('/Users/virajdatt/Desktop/github/public/Machine-Hack-/uHack-Sentiments/data/train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "raw_data['Review'].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    For some reason everybody complains and I'm co...\n",
       "1    I like everything about it, great choice of sp...\n",
       "2    Excellent ceiling fan brace. Easy to install a...\n",
       "3    Work great easy to use . No issues at all with...\n",
       "4    I would recommend this product because it is p...\n",
       "Name: Review, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Following are the labels in the dataset\n",
    "mlabels = ['Components', 'Delivery and Customer Support',\n",
    "       'Design and Aesthetics', 'Dimensions', 'Features', 'Functionality',\n",
    "       'Installation', 'Material', 'Price', 'Quality', 'Usability']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Cleanup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert all text to lowercase\n",
    "raw_data['Review'] = text_ops.lowercase_column(raw_data, 'Review')\n",
    "# Clean the data\n",
    "raw_data['Review'] = raw_data['Review'].apply(text_ops.clean_up)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Preprocessing (Vectorizing)\n",
    "1. Split data into train and validation set.\n",
    "2. Apply the TFIDF on the train set (avoid invovling the validation part here as it leads to data leakage)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "train, test = train_test_split(raw_data,\n",
    "                               random_state=69,\n",
    "                               test_size=0.2,\n",
    "                               shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "tfidf = Pipeline(steps=[\n",
    "                        ('tfidf', \n",
    "                        TfidfVectorizer(strip_accents='unicode', \n",
    "                                                analyzer='word', \n",
    "                                                ngram_range=(1,3), \n",
    "                                                norm='l2'))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling\n",
    "### 1. Binary Relevance\n",
    "### 2. Classifier Chains\n",
    "### 3. Label Powerset\n",
    "\n",
    "## Adapted Algorithm \n",
    "\n",
    "### 1. ML-KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "clf = Pipeline(steps=[(\n",
    "                        'GNB', classifier\n",
    ")])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "pipeline1 = Pipeline(steps=[\n",
    "    ('preprocess', tfidf),\n",
    "    ('classifier', clf)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "pipeline1.fit(train['Review'], train[mlabels])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess', Pipeline(steps=[('tfidf', TfidfVectorizer())])),\n",
       "                ('classifier',\n",
       "                 Pipeline(steps=[('GNB',\n",
       "                                  BinaryRelevance(classifier=GaussianNB(),\n",
       "                                                  require_dense=[True,\n",
       "                                                                 True]))]))])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "prediction = pipeline1.predict(test['Review'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "print(\"Accuracy = \",accuracy_score(test[mlabels],prediction))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.04478827361563518\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "classifier_new = MLkNN(k=10)\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit(raw_data['Review'])\n",
    "vectorizer.fit(raw_data['Review'])\n",
    "\n",
    "x_train = vectorizer.transform(raw_data['Review'])\n",
    "y_train = raw_data[mlabels]\n",
    "\n",
    "# x_test = vectorizer.transform(test['Review'])\n",
    "# y_test = test[mlabels]\n",
    "\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "#x_test = lil_matrix(x_test).toarray()\n",
    "\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "# predict\n",
    "# predictions_new = classifier_new.predict(x_test)\n",
    "# # accuracy\n",
    "# print(\"Accuracy = \",accuracy_score(y_test,predictions_new))\n",
    "# print(\"\\n\")\n",
    "#log_loss(y_test,predictions_new.todense())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/virajdatt/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLkNN()"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "test_data = pd.read_csv('/Users/virajdatt/Desktop/github/public/Machine-Hack-/uHack-Sentiments/data/test.csv')\n",
    "test_array = vectorizer.transform(test_data['Review'])\n",
    "test_array = lil_matrix(test_array).toarray()\n",
    "\n",
    "final_pred = classifier_new.predict(test_array)\n",
    "#pd.DataFrame.sparse.from_spmatrix(final_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "test_data[mlabels] = pd.DataFrame.sparse.from_spmatrix(final_pred)\n",
    "test_data['Polarity'] = test_data['Review'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "\n",
    "def bin_polarity(data):\n",
    "    if data < 0.5:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0\n",
    "test_data['Polarity'] = test_data['Polarity'].apply(bin_polarity)\n",
    "mlabels.append('Polarity')\n",
    "#test_data[mlabels] = pd.to_numeric(test_data[mlabels])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "test_data[mlabels]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2631 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Components  Delivery and Customer Support  Design and Aesthetics  \\\n",
       "0              0                              0                      0   \n",
       "1              0                              0                      0   \n",
       "2              0                              0                      0   \n",
       "3              0                              0                      0   \n",
       "4              0                              0                      0   \n",
       "...          ...                            ...                    ...   \n",
       "2626           0                              0                      0   \n",
       "2627           0                              0                      0   \n",
       "2628           0                              0                      0   \n",
       "2629           0                              0                      0   \n",
       "2630           0                              0                      0   \n",
       "\n",
       "      Dimensions  Features  Functionality  Installation  Material  Price  \\\n",
       "0              0         0              0             0         0      0   \n",
       "1              0         0              1             0         0      0   \n",
       "2              0         0              0             0         0      0   \n",
       "3              0         0              1             0         0      0   \n",
       "4              0         0              1             0         0      0   \n",
       "...          ...       ...            ...           ...       ...    ...   \n",
       "2626           0         0              0             1         0      0   \n",
       "2627           0         0              0             0         0      0   \n",
       "2628           0         0              0             0         0      0   \n",
       "2629           0         0              0             0         0      0   \n",
       "2630           0         0              0             1         0      0   \n",
       "\n",
       "      Quality  Usability  Polarity  \n",
       "0           0          0       0.0  \n",
       "1           0          0       1.0  \n",
       "2           0          1       0.0  \n",
       "3           0          0       0.0  \n",
       "4           0          0       0.0  \n",
       "...       ...        ...       ...  \n",
       "2626        0          0       0.0  \n",
       "2627        0          0       0.0  \n",
       "2628        1          0       1.0  \n",
       "2629        1          0       0.0  \n",
       "2630        0          0       0.0  \n",
       "\n",
       "[2631 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "test_data[mlabels].to_csv('/Users/virajdatt/Desktop/github/public/Machine-Hack-/uHack-Sentiments/submissions/baseline2.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# using Label Powerset\n",
    "\n",
    "# initialize label powerset multi-label classifier\n",
    "classifier2 = LabelPowerset(LogisticRegression())\n",
    "# train\n",
    "\n",
    "pipeline2 = Pipeline(steps=[\n",
    "    ('preprocess', tfidf),\n",
    "    ('classifier', classifier2)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "pipeline1.fit(train['Review'], train[mlabels])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess', Pipeline(steps=[('tfidf', TfidfVectorizer())])),\n",
       "                ('classifier',\n",
       "                 LabelPowerset(classifier=LogisticRegression(),\n",
       "                               require_dense=[True, True]))])"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "#pipeline1.score(test['Review'], test[mlabels])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "#log_loss(pipeline1.predict(test['Review']), test[mlabels])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Important Liks\n",
    "[TFIDF on train or train+test](!https://stats.stackexchange.com/questions/154660/tfidfvectorizer-should-it-be-used-on-train-only-or-traintest)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "78626e5cb14307b2371f3946c1caa5bbc168a9eda33df78f60dc6faeb16eeee6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}